{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebe8c779-9878-4368-b0c4-3706758d2ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plate</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>price_Box-Cox</th>\n",
       "      <th>price_Yeo-Johnson</th>\n",
       "      <th>price_Quantile</th>\n",
       "      <th>price_log</th>\n",
       "      <th>plate_length</th>\n",
       "      <th>region</th>\n",
       "      <th>registration_code</th>\n",
       "      <th>...</th>\n",
       "      <th>series_part_2_YC</th>\n",
       "      <th>series_part_2_YE</th>\n",
       "      <th>series_part_2_YH</th>\n",
       "      <th>series_part_2_YK</th>\n",
       "      <th>series_part_2_YM</th>\n",
       "      <th>series_part_2_YO</th>\n",
       "      <th>series_part_2_YP</th>\n",
       "      <th>series_part_2_YT</th>\n",
       "      <th>series_part_2_YX</th>\n",
       "      <th>series_part_2_YY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X059CP797</td>\n",
       "      <td>2024-12-26 00:00:00</td>\n",
       "      <td>65000</td>\n",
       "      <td>-0.903094</td>\n",
       "      <td>-0.903096</td>\n",
       "      <td>-0.817902</td>\n",
       "      <td>11.082158</td>\n",
       "      <td>9</td>\n",
       "      <td>797</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y800MH790</td>\n",
       "      <td>2024-07-12 21:31:37</td>\n",
       "      <td>100000</td>\n",
       "      <td>-0.440378</td>\n",
       "      <td>-0.440380</td>\n",
       "      <td>-0.370902</td>\n",
       "      <td>11.512935</td>\n",
       "      <td>9</td>\n",
       "      <td>790</td>\n",
       "      <td>800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A212TX77</td>\n",
       "      <td>2024-04-18 00:00:00</td>\n",
       "      <td>290000</td>\n",
       "      <td>0.532677</td>\n",
       "      <td>0.532678</td>\n",
       "      <td>0.468203</td>\n",
       "      <td>12.577640</td>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P001AY199</td>\n",
       "      <td>2025-01-03 00:27:15</td>\n",
       "      <td>680000</td>\n",
       "      <td>1.196486</td>\n",
       "      <td>1.163831</td>\n",
       "      <td>1.149742</td>\n",
       "      <td>13.429850</td>\n",
       "      <td>9</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B400BB750</td>\n",
       "      <td>2022-04-09 00:00:00</td>\n",
       "      <td>50000</td>\n",
       "      <td>-1.207010</td>\n",
       "      <td>-1.207011</td>\n",
       "      <td>-1.184447</td>\n",
       "      <td>10.819798</td>\n",
       "      <td>9</td>\n",
       "      <td>750</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       plate                 date   price  price_Box-Cox  price_Yeo-Johnson  \\\n",
       "0  X059CP797  2024-12-26 00:00:00   65000      -0.903094          -0.903096   \n",
       "1  Y800MH790  2024-07-12 21:31:37  100000      -0.440378          -0.440380   \n",
       "2   A212TX77  2024-04-18 00:00:00  290000       0.532677           0.532678   \n",
       "3  P001AY199  2025-01-03 00:27:15  680000       1.196486           1.163831   \n",
       "4  B400BB750  2022-04-09 00:00:00   50000      -1.207010          -1.207011   \n",
       "\n",
       "   price_Quantile  price_log  plate_length  region  registration_code  ...  \\\n",
       "0       -0.817902  11.082158             9     797                 59  ...   \n",
       "1       -0.370902  11.512935             9     790                800  ...   \n",
       "2        0.468203  12.577640             8      77                212  ...   \n",
       "3        1.149742  13.429850             9     199                  1  ...   \n",
       "4       -1.184447  10.819798             9     750                400  ...   \n",
       "\n",
       "  series_part_2_YC series_part_2_YE series_part_2_YH series_part_2_YK  \\\n",
       "0              0.0              0.0              0.0              0.0   \n",
       "1              0.0              0.0              0.0              0.0   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.0              0.0              0.0              0.0   \n",
       "4              0.0              0.0              0.0              0.0   \n",
       "\n",
       "   series_part_2_YM  series_part_2_YO  series_part_2_YP  series_part_2_YT  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   series_part_2_YX  series_part_2_YY  \n",
       "0               0.0               0.0  \n",
       "1               0.0               0.0  \n",
       "2               0.0               0.0  \n",
       "3               0.0               0.0  \n",
       "4               0.0               0.0  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('feature_extracted_plate.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c75c5d99-969f-430b-a0e3-a40ed0bfe85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'E': 3,\n",
       " 'H': 4,\n",
       " 'K': 5,\n",
       " 'M': 6,\n",
       " 'O': 7,\n",
       " 'P': 8,\n",
       " 'T': 9,\n",
       " 'X': 10,\n",
       " 'Y': 11}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_plate = ['A', 'B', 'C', 'E', 'H', 'K', 'M', 'O', 'P', 'T', 'X', 'Y']\n",
    "char2idx = {char: idx for idx, char in enumerate(char_plate)}\n",
    "char2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c739ba-4ab4-4dae-a63f-5fc6cd07176d",
   "metadata": {},
   "source": [
    "# Utilize the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12cdf6b3-d20e-4f2f-b111-5c4b5cf4df82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=8, bias=True)\n",
       "    (1): Linear(in_features=8, out_features=16, bias=True)\n",
       "    (2): Linear(in_features=16, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (7): Linear(in_features=8, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(3, 8),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(128, 256),\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            #nn.Linear(256, 128),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(8, 3),\n",
    "            # nn.ReLU(),  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        return self.decoder(out)\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "# Best Model:\n",
    "autoencoder.load_state_dict(torch.load(\"2_0.00014334209845401347.pth\"))\n",
    "autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3585243e-645d-4587-9c7d-ecbb12c0e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_encoder = autoencoder.encoder\n",
    "\n",
    "for param in pretrained_encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "4c32dc17-ca8f-48c0-89cf-24e4fc9c0715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, encoder):\n",
    "        super(BaseModel, self).__init__()\n",
    "\n",
    "        # Our pretrained model:\n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.ffn_encoder = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.ffn_base = nn.Sequential(\n",
    "            nn.Linear(3, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1),\n",
    "            #nn.ReLU(),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, series, region, registration):\n",
    "        with torch.no_grad():\n",
    "            encoder_out = self.encoder(series)\n",
    "\n",
    "        encoder_ffn_out = self.ffn_encoder(encoder_out)\n",
    "    \n",
    "        input_ffn_base = torch.cat((encoder_ffn_out, region, registration), dim=1)\n",
    "        out = self.ffn_base(input_ffn_base)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "9f695a85-1d7e-46d5-8efb-fc9193643bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class CarPlateDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.loc[:,['series', 'region', 'registration_code', 'price']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        series = self.data.iloc[idx]['series']\n",
    "        region = self.data.iloc[idx]['region']\n",
    "        registration = self.data.iloc[idx]['registration_code']\n",
    "        price = self.data.iloc[idx]['price']\n",
    "\n",
    "\n",
    "        series_tensor = torch.tensor([char2idx[char] for char in series], dtype=torch.float32)\n",
    "        region_tensor = torch.tensor([region], dtype=torch.float32)\n",
    "        registration_tensor = torch.tensor([registration], dtype=torch.float32)\n",
    "        price_tensor = torch.tensor([price], dtype=torch.float32)\n",
    "        \n",
    "\n",
    "        return series_tensor, region_tensor, registration_tensor, price_tensor\n",
    "\n",
    "dataset = CarPlateDataset(df)\n",
    "batch_size = 62\n",
    "k_folds = 3\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f62ad-8a8f-446c-84c5-135d3e524204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "bb0ad069-bff0-4240-a216-4228b1782650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMAPELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SMAPELoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Compute the denominator: (|y_true| + |y_pred|) / 2.0\n",
    "        denominator = (torch.abs(y_true) + torch.abs(y_pred)) / 2.0\n",
    "        \n",
    "        # Use torch.where to avoid division by zero:\n",
    "        # When denominator is 0, we assign 0 to the difference.\n",
    "        diff = torch.where(denominator == 0, \n",
    "                           torch.zeros_like(denominator),\n",
    "                           torch.abs(y_true - y_pred) / denominator)\n",
    "        \n",
    "        # Calculate mean SMAPE and scale by 100\n",
    "        loss = torch.mean(diff) * 100.0\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "1996a78c-963d-41cd-bc9f-be3d92f6ad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Epoch [1/100] Train Loss: 154.3416, Val Loss: 134.1431\n",
      "Epoch [2/100] Train Loss: 134.7025, Val Loss: 134.3810\n",
      "Epoch [3/100] Train Loss: 133.3387, Val Loss: 134.5887\n",
      "Epoch [4/100] Train Loss: 132.8149, Val Loss: 136.8652\n",
      "Epoch [5/100] Train Loss: 133.2413, Val Loss: 132.3155\n",
      "Epoch [6/100] Train Loss: 132.1683, Val Loss: 132.1595\n",
      "Epoch [7/100] Train Loss: 131.6486, Val Loss: 130.5738\n",
      "Epoch [8/100] Train Loss: 130.9788, Val Loss: 130.3078\n",
      "Epoch [9/100] Train Loss: 130.5050, Val Loss: 131.6272\n",
      "Epoch [10/100] Train Loss: 130.1069, Val Loss: 129.1567\n",
      "Epoch [11/100] Train Loss: 129.3267, Val Loss: 127.8862\n",
      "Epoch [12/100] Train Loss: 127.8502, Val Loss: 126.6739\n",
      "Epoch [13/100] Train Loss: 126.3250, Val Loss: 145.7111\n",
      "Epoch [14/100] Train Loss: 121.1242, Val Loss: 108.8968\n",
      "Epoch [15/100] Train Loss: 91.5599, Val Loss: 71.7503\n",
      "Epoch [16/100] Train Loss: 75.1386, Val Loss: 69.7966\n",
      "Epoch [17/100] Train Loss: 72.9673, Val Loss: 71.8166\n",
      "Epoch [18/100] Train Loss: 71.6896, Val Loss: 70.7042\n",
      "Epoch [19/100] Train Loss: 71.1928, Val Loss: 70.3344\n",
      "Epoch [20/100] Train Loss: 70.4599, Val Loss: 68.6439\n",
      "Epoch [21/100] Train Loss: 70.5120, Val Loss: 69.2932\n",
      "Epoch [22/100] Train Loss: 70.4989, Val Loss: 69.4033\n",
      "Epoch [23/100] Train Loss: 69.9236, Val Loss: 69.1404\n",
      "Epoch [24/100] Train Loss: 70.1726, Val Loss: 73.2583\n",
      "Epoch [25/100] Train Loss: 69.9204, Val Loss: 69.2310\n",
      "Epoch [26/100] Train Loss: 69.7491, Val Loss: 70.3612\n",
      "Epoch [27/100] Train Loss: 69.6085, Val Loss: 71.2120\n",
      "Epoch [28/100] Train Loss: 69.6930, Val Loss: 69.0798\n",
      "Epoch [29/100] Train Loss: 69.2485, Val Loss: 70.3248\n",
      "Epoch [30/100] Train Loss: 69.9223, Val Loss: 70.0479\n",
      "Epoch [31/100] Train Loss: 69.2925, Val Loss: 68.6540\n",
      "Epoch [32/100] Train Loss: 69.4452, Val Loss: 68.9630\n",
      "Epoch [33/100] Train Loss: 69.5347, Val Loss: 71.3424\n",
      "Epoch [34/100] Train Loss: 69.5480, Val Loss: 68.9357\n",
      "Epoch [35/100] Train Loss: 69.1448, Val Loss: 70.2853\n",
      "Epoch [36/100] Train Loss: 69.0366, Val Loss: 71.2653\n",
      "Epoch [37/100] Train Loss: 69.4314, Val Loss: 70.6759\n",
      "Epoch [38/100] Train Loss: 69.2962, Val Loss: 68.7701\n",
      "Epoch [39/100] Train Loss: 68.8315, Val Loss: 68.7304\n",
      "Epoch [40/100] Train Loss: 68.9156, Val Loss: 70.6556\n",
      "Epoch [41/100] Train Loss: 68.8341, Val Loss: 68.7948\n",
      "Epoch [42/100] Train Loss: 68.7365, Val Loss: 70.9506\n",
      "Epoch [43/100] Train Loss: 68.9593, Val Loss: 70.7624\n",
      "Epoch [44/100] Train Loss: 68.9334, Val Loss: 68.8046\n",
      "Epoch [45/100] Train Loss: 68.9150, Val Loss: 71.1423\n",
      "Epoch [46/100] Train Loss: 68.9502, Val Loss: 68.6159\n",
      "Epoch [47/100] Train Loss: 68.6318, Val Loss: 68.3628\n",
      "Epoch [48/100] Train Loss: 68.7368, Val Loss: 68.5591\n",
      "Epoch [49/100] Train Loss: 68.7110, Val Loss: 68.7561\n",
      "Epoch [50/100] Train Loss: 68.8535, Val Loss: 68.2637\n",
      "Epoch [51/100] Train Loss: 68.3988, Val Loss: 68.5993\n",
      "Epoch [52/100] Train Loss: 68.6887, Val Loss: 71.0928\n",
      "Epoch [53/100] Train Loss: 68.4609, Val Loss: 69.5523\n",
      "Epoch [54/100] Train Loss: 68.5052, Val Loss: 68.1044\n",
      "Epoch [55/100] Train Loss: 68.2781, Val Loss: 69.5454\n",
      "Epoch [56/100] Train Loss: 68.5803, Val Loss: 69.2895\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[314], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     13\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m series, region, registration, price \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     15\u001b[0m     targets \u001b[38;5;241m=\u001b[39m price  \u001b[38;5;66;03m# price is in original scale\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Forward pass: model outputs log(price) values\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[298], line 23\u001b[0m, in \u001b[0;36mCarPlateDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m series_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([char2idx[char] \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m series], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     22\u001b[0m region_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([region], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 23\u001b[0m registration_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([registration], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     24\u001b[0m price_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([price], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m series_tensor, region_tensor, registration_tensor, price_tensor\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f'\\n=== Fold {fold+1} ===')\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for series, region, registration, price in train_loader:\n",
    "            targets = price  # price is in original scale\n",
    "\n",
    "            # Forward pass: model outputs log(price) values\n",
    "            outputs = model(series, region, registration)\n",
    "            \n",
    "            preds = torch.exp(outputs)\n",
    "            \n",
    "            # Now compute loss between original-scale predictions and targets\n",
    "            loss = criterion(preds, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * series.size(0)\n",
    "\n",
    "        train_loss /= len(train_subset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for series, region, registration, price in val_loader:\n",
    "                targets = price\n",
    "                log_preds = model(series, region, registration)\n",
    "                preds = torch.exp(log_preds)\n",
    "                \n",
    "                loss = criterion(preds, targets)\n",
    "                val_loss += loss.item() * series.size(0)\n",
    "            \n",
    "        val_loss /= len(val_subset)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7d789e70-7ca6-4576-882f-7bbf22c734e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Epoch [1/100] Train Loss: 200.0000, Val Loss: 200.0000\n",
      "Epoch [2/100] Train Loss: 200.0000, Val Loss: 200.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[310], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     25\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m series, region, registration, price \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     27\u001b[0m     targets \u001b[38;5;241m=\u001b[39m price  \u001b[38;5;66;03m# Your target values\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(series, region, registration)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[298], line 17\u001b[0m, in \u001b[0;36mCarPlateDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m region \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m registration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistration_code\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m series_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([char2idx[char] \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m series], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1754\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:3996\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3994\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[1;32m   3995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3996\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mfast_xs(i)\n\u001b[1;32m   3998\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3999\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:984\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    976\u001b[0m     block \u001b[38;5;241m=\u001b[39m new_block(\n\u001b[1;32m    977\u001b[0m         result,\n\u001b[1;32m    978\u001b[0m         placement\u001b[38;5;241m=\u001b[39mbp,\n\u001b[1;32m    979\u001b[0m         ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    980\u001b[0m         refs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mrefs,\n\u001b[1;32m    981\u001b[0m     )\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SingleBlockManager(block, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 984\u001b[0m dtype \u001b[38;5;241m=\u001b[39m interleaved_dtype([blk\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks])\n\u001b[1;32m    986\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m# TODO: use object dtype as workaround for non-performant\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m#  EA.__setitem__ methods. (primarily ArrowExtensionArray.__setitem__\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m#  when iteratively setting individual values)\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;66;03m#  https://github.com/pandas-dev/pandas/pull/54508#issuecomment-1675827918\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/base.py:394\u001b[0m, in \u001b[0;36minterleaved_dtype\u001b[0;34m(dtypes)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dtypes):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m find_common_type(dtypes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:1461\u001b[0m, in \u001b[0;36mfind_common_type\u001b[0;34m(types)\u001b[0m\n\u001b[1;32m   1458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m first\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;66;03m# get unique types (dict.fromkeys is used as order-preserving set())\u001b[39;00m\n\u001b[0;32m-> 1461\u001b[0m types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mfromkeys(types)\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(t, ExtensionDtype) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "model = BaseModel(pretrained_encoder)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "criterion = SMAPELoss()\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f'\\n=== Fold {fold+1} ===')\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "    # You can use your SMAPE loss or, if you want to compare, MSELoss\n",
    "    # criterion = nn.MSELoss()  # Original loss\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for series, region, registration, price in train_loader:\n",
    "            targets = price  # Your target values\n",
    "            outputs = model(series, region, registration)\n",
    "\n",
    "            loss = criterion(outputs, targets)  # Use SMAPE loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * series.size(0)\n",
    "\n",
    "        train_loss /= len(train_subset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for series, region, registration, price in val_loader:\n",
    "                targets = price\n",
    "                outputs = model(series, region, registration)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * series.size(0)\n",
    "            \n",
    "        val_loss /= len(val_subset)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "25a6b070-4371-48ce-8c21-ea74d49faf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'base_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ce0f6be1-11b6-442a-b580-63283c16ed66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>plate</th>\n",
       "      <th>price</th>\n",
       "      <th>series</th>\n",
       "      <th>region</th>\n",
       "      <th>registration_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51636</td>\n",
       "      <td>P700TT790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PTT</td>\n",
       "      <td>790</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51637</td>\n",
       "      <td>M081TX797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTX</td>\n",
       "      <td>797</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51638</td>\n",
       "      <td>T333HX777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THX</td>\n",
       "      <td>777</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51639</td>\n",
       "      <td>H744BH977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HBH</td>\n",
       "      <td>977</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51640</td>\n",
       "      <td>X066EM777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XEM</td>\n",
       "      <td>777</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      plate  price series  region  registration_code\n",
       "0  51636  P700TT790    NaN    PTT     790                700\n",
       "1  51637  M081TX797    NaN    MTX     797                 81\n",
       "2  51638  T333HX777    NaN    THX     777                333\n",
       "3  51639  H744BH977    NaN    HBH     977                744\n",
       "4  51640  X066EM777    NaN    XEM     777                 66"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('test.csv').drop('date', axis=1)\n",
    "\n",
    "df_test['series'] = df_test['plate'].apply(lambda x: x[0] + x[4:6])\n",
    "df_test['region'] = df_test['plate'].apply(lambda x: int(x[-2:]) if len(x) == 8 else int(x[-3:]))\n",
    "df_test['registration_code'] = df_test['plate'].apply(lambda x: int(x[1:4]))\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d5aa57b2-f7b3-4801-8010-c3175b26d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCarPlateDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.loc[:, ['series', 'region', 'registration_code']]\n",
    "        self.original_indices = data.index  # If you want to keep original indices/IDs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        series_tensor = torch.tensor([char2idx[char] for char in row['series']], dtype=torch.float32)\n",
    "        region_tensor = torch.tensor([row['region']], dtype=torch.float32)\n",
    "        registration_tensor = torch.tensor([row['registration_code']], dtype=torch.float32)\n",
    "\n",
    "        return series_tensor, region_tensor, registration_tensor\n",
    "\n",
    "\n",
    "test_dataset = TestCarPlateDataset(df_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "167e8090-5837-4aba-94fb-27ef006ba6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for series, region, registration in test_loader:\n",
    "        outputs = model(series, region, registration)\n",
    "        predictions.append(outputs.cpu())\n",
    "\n",
    "# Flatten predictions to numpy\n",
    "preds = torch.cat(predictions).numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ea70b0fe-7665-4b46-a323-b4fcc684d33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 81451.48 ,  70880.766,  66767.32 , ...,  68909.445, 198048.75 ,\n",
       "        74699.76 ], dtype=float32)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d5eb71f5-a2a7-4b59-8913-12672770dbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51636</td>\n",
       "      <td>81451.476562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51637</td>\n",
       "      <td>70880.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51638</td>\n",
       "      <td>66767.320312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51639</td>\n",
       "      <td>76502.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51640</td>\n",
       "      <td>70673.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7690</th>\n",
       "      <td>59326</td>\n",
       "      <td>107165.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691</th>\n",
       "      <td>59327</td>\n",
       "      <td>70551.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7692</th>\n",
       "      <td>59328</td>\n",
       "      <td>68909.445312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7693</th>\n",
       "      <td>59329</td>\n",
       "      <td>198048.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>59330</td>\n",
       "      <td>74699.757812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7695 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id          price\n",
       "0     51636   81451.476562\n",
       "1     51637   70880.765625\n",
       "2     51638   66767.320312\n",
       "3     51639   76502.976562\n",
       "4     51640   70673.804688\n",
       "...     ...            ...\n",
       "7690  59326  107165.117188\n",
       "7691  59327   70551.203125\n",
       "7692  59328   68909.445312\n",
       "7693  59329  198048.750000\n",
       "7694  59330   74699.757812\n",
       "\n",
       "[7695 rows x 2 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'id': df_test.id,\n",
    "    'price': preds\n",
    "})\n",
    "\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "694cd883-43f6-4b98-ab1e-2594c66989ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('test_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
